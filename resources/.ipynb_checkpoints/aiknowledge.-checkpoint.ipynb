{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "# create DataFrame from python list. It can infer schema for you.\n",
        "df1 = spark.createDataFrame([(1, \"andy\", 20, \"USA\"), (2, \"jeff\", 23, \"China\"), (3, \"james\", 18, \"USA\")]).toDF(\"id\", \"name\", \"age\", \"country\")\n",
        "df1.printSchema()\n",
        "df1.show()\n",
        "\n",
        "# create DataFrame from pandas dataframe\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "df2=spark.read.parquet('/test/wiki.parquet')\n",
        "\n",
        "df2.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "sc.getConf().getAll()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "df1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "df2.write.saveAsTable('wiki')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "spark.sql('select * from wiki').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%sql\n",
        "select * from wiki;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%sql\n",
        "show tables;\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spylon-kernel",
      "language": "scala",
      "name": "spylon-kernel"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "aiknowledge"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
