{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91nh7X7gACuG"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX1rBbPTACuH"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/8.Keyword_Extraction_YAKE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKn131CHyyJS"
   },
   "source": [
    "# 8 Keyword Extraction with YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3478,
     "status": "ok",
     "timestamp": 1664989393532,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "9LPdKxwMiUOd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spark-nlp-jsl 4.2.2 requires spark-nlp==4.2.2, but you have spark-nlp 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip install -q pyspark==3.3.0 spark-nlp==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1664989393880,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "z_S72s4234Cs"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType, DataType,ArrayType\n",
    "from pyspark.sql.functions import udf, struct\n",
    "from pyspark.ml import Pipeline\n",
    "from IPython.display import display, HTML\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "executionInfo": {
     "elapsed": 31656,
     "status": "ok",
     "timestamp": 1664989425533,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "8DFCYTaDC1qZ",
    "outputId": "e4502f32-5c60-4610-93ef-8b95bb0a47d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 15:44:39 WARN Utils: Your hostname, Glorias-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.39 instead (on interface en0)\n",
      "22/11/18 15:44:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/gloria/opt/anaconda3/envs/pyspark/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/gloria/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/gloria/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c8120f3d-e2ad-4928-82e0-7e08c3738fea;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      "\tfound org.postgresql#postgresql;42.5.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/4.2.3/spark-nlp_2.12-4.2.3.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.3!spark-nlp_2.12.jar (448819ms)\n",
      ":: resolution report :: resolve 2400ms :: artifacts dl 448871ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.2.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.5.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   19  |   1   |   1   |   0   ||   19  |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c8120f3d-e2ad-4928-82e0-7e08c3738fea\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 18 already retrieved (43981kB/171ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 15:52:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 15:52:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "Spark NLP version 4.2.0\n",
      "Apache Spark version: 3.3.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.39:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9eabd69cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "# spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.3,org.postgresql:postgresql:42.5.0\")\\\n",
    "    .getOrCreate()\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1664989425534,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "iOJU1xf-D5D8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 16:08:07 WARN StopWordsCleaner: Default locale set was [zh_KR_#Hans]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "stopwords = StopWordsCleaner().getStopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664989425534,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "KCigxYJTD_RQ",
    "outputId": "cf9580f0-bbda-4467-cb63-71fbf6ddb131"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QPZpoZDyyJz"
   },
   "source": [
    "## YAKE Keyword Extractor\n",
    "\n",
    "Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm.\n",
    "\n",
    "Extracting keywords from texts has become a challenge for individuals and organizations as the information grows in complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised approach which builds upon features extracted from the text, making it thus applicable to documents written in different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a plethora of situations where access to training corpora is either limited or restricted.\n",
    "\n",
    "\n",
    "The algorithm makes use of the position of a sentence and token. Therefore, to use the annotator, the text should be first sent through a Sentence Boundary Detector and then a tokenizer.\n",
    "\n",
    "You can tweak the following parameters to get the best result from the annotator.\n",
    "\n",
    "- *setMinNGrams(int)* Select the minimum length of a extracted keyword\n",
    "- *setMaxNGrams(int)* Select the maximum length of a extracted keyword\n",
    "- *setNKeywords(int)* Extract the top N keywords\n",
    "- *setStopWords(list)* Set the list of stop words\n",
    "- *setThreshold(float)* Each keyword will be given a keyword score greater than 0. (Lower the score better the keyword) Set an upper bound for the keyword score from this method.\n",
    "- *setWindowSize(int)* Yake will construct a co-occurence matrix. You can set the window size for the cooccurence matrix construction from this method. ex: windowSize=2 will look at two words to both left and right of a candidate word.\n",
    "\n",
    "\n",
    "<b>References</b>\n",
    "\n",
    "Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. [pdf](https://doi.org/10.1016/j.ins.2019.09.013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6019,
     "status": "ok",
     "timestamp": 1664989431542,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "ConWEw-aACul"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/gloria/opt/anaconda3/envs/pyspark/lib/python3.9/site-packages/pyspark/jars/spark-core_2.12-3.3.0.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "            .setInputCols(\"document\") \\\n",
    "            .setOutputCol(\"sentence\")\n",
    "\n",
    "token = Tokenizer() \\\n",
    "            .setInputCols(\"sentence\") \\\n",
    "            .setOutputCol(\"token\") \\\n",
    "            .setContextChars([\"(\", \")\", \"?\", \"!\", \".\", \",\"])\n",
    "\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "            .setInputCols(\"token\") \\\n",
    "            .setOutputCol(\"keywords\") \\\n",
    "            .setMinNGrams(1) \\\n",
    "            .setMaxNGrams(3)\\\n",
    "            .setNKeywords(20)\\\n",
    "            .setStopWords(stopwords)\n",
    "\n",
    "yake_pipeline = Pipeline(stages=[document, sentenceDetector, token, keywords])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "yake_Model = yake_pipeline.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20619,
     "status": "ok",
     "timestamp": 1664989452152,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "xHKXF9jwzkjb",
    "outputId": "0e45d719-4f8d-494a-f4bc-2d23d9411e7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Then the LORD said, \"The outcry against Sodom and Gomorrah is so great and their sin so grievous')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightPipeline\n",
    "\n",
    "light_model = LightPipeline(yake_Model)\n",
    "\n",
    "text = '''\n",
    "Then the LORD said, \"The outcry against Sodom and Gomorrah is so great and their sin so grievous'''\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "[(s.metadata['sentence'], s.result) for s in light_result['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'sentence', 'token', 'keywords'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_result.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.createDataFrame(data=light_result,schema=[['document', 'sentence', 'token', 'keywords']])\n",
    "# df.printSchema()\n",
    "# df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1664989452153,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "S1TBn41yzyXB",
    "outputId": "09d5df29-240e-48d9-8326-df2edd97642b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grievous</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>0.393326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lord said</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.440864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lord</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.475870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sodom</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>0.475870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gomorrah</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>0.475870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0.642974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outcry</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>0.642974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>0.642974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sin</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>0.642974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sodom and gomorrah</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>0.907923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sin so grievous</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>0.953428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>outcry against sodom</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>1.207229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                keywords  begin  end     score sentence\n",
       "7               grievous     89   96  0.393326        0\n",
       "8              lord said     10   18  0.440864        0\n",
       "0                   lord     10   13  0.475870        0\n",
       "3                  sodom     41   45  0.475870        0\n",
       "4               gomorrah     51   58  0.475870        0\n",
       "1                   said     15   18  0.642974        0\n",
       "2                 outcry     26   31  0.642974        0\n",
       "5                  great     66   70  0.642974        0\n",
       "6                    sin     82   84  0.642974        0\n",
       "10    sodom and gomorrah     41   58  0.907923        0\n",
       "11       sin so grievous     82   96  0.953428        0\n",
       "9   outcry against sodom     26   45  1.207229        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keys_df = pd.DataFrame([(k.result, k.begin, k.end, k.metadata['score'],  k.metadata['sentence']) for k in light_result['keywords']],\n",
    "                       columns = ['keywords','begin','end','score','sentence'])\n",
    "keys_df['score'] = keys_df['score'].astype(float)\n",
    "\n",
    "# ordered by relevance \n",
    "keys_df.sort_values(['sentence','score']).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0iVE9qt1Vmq"
   },
   "source": [
    "### Getting keywords from datraframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4122,
     "status": "ok",
     "timestamp": 1664989456244,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "ldRBUp-w1Z8U",
    "outputId": "a97053ce-9a1c-4a57-f930-8d5efff7aab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed_sample_text_small.csv\n",
    "\n",
    "df = spark.read.csv(\"../data/bibleNIV.csv\")\\\n",
    "                \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|In the beginning ...|\n",
      "|Now the earth was...|\n",
      "|And God said, \"Le...|\n",
      "|God saw that the ...|\n",
      "|God called the li...|\n",
      "|And God said, \"Le...|\n",
      "|So God made the e...|\n",
      "|God called the ex...|\n",
      "|And God said, \"Le...|\n",
      "|God called the dr...|\n",
      "|Then God said, \"L...|\n",
      "|The land produced...|\n",
      "|And there was eve...|\n",
      "|And God said, \"Le...|\n",
      "|and let them be l...|\n",
      "|God made two grea...|\n",
      "|God set them in t...|\n",
      "|to govern the day...|\n",
      "|And there was eve...|\n",
      "|And God said, \"Le...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.selectExpr('_c3 as text')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1664989456973,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "9hF78PwHzM2v"
   },
   "outputs": [],
   "source": [
    "result = yake_pipeline.fit(df2).transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1664989456974,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "JIG80DeiACuo"
   },
   "outputs": [],
   "source": [
    "result = result.withColumn('unique_keywords', F.array_distinct(\"keywords.result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664989456974,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "S99DR0U6ACur"
   },
   "outputs": [],
   "source": [
    "def highlight(text, keywords):\n",
    "    for k in keywords:\n",
    "        text = (re.sub(r'(\\b%s\\b)'%k, r'<span style=\"background-color: yellow;\">\\1</span>', text, flags=re.IGNORECASE))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664989456975,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "jBJrnYPSACut"
   },
   "outputs": [],
   "source": [
    "highlight_udf = udf(highlight, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664989456975,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "nqavzZpbACuv"
   },
   "outputs": [],
   "source": [
    "result = result.withColumn(\"highlighted_keywords\",highlight_udf('text','unique_keywords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- unique_keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- highlighted_keywords: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.json('bibleKeyword.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>unique_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "      <td>[beginning, god, created, heavens, earth, begi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now the earth was formless and empty, darkness...</td>\n",
       "      <td>[earth, formless, empty, darkness, surface, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And God said, \"Let there be light,\" and there ...</td>\n",
       "      <td>[god, said, light, god said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God saw that the light was good, and He separa...</td>\n",
       "      <td>[god, saw, light, good, separated, darkness, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>God called the light \"day,\" and the darkness h...</td>\n",
       "      <td>[god, called, light, darkness, evening, first,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   text                                                                                                                                            unique_keywords\n",
       "0                                                                               In the beginning God created the heavens and the earth.                                          [beginning, god, created, heavens, earth, beginning god, god created, beginning god created, created the heavens]\n",
       "1  Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.  [earth, formless, empty, darkness, surface, deep, spirit, god, hovering, waters, earth was formless, formless and empty, spirit of god, god was hovering]\n",
       "2                                                                              And God said, \"Let there be light,\" and there was light.                                                                                                                               [god, said, light, god said]\n",
       "3                                                        God saw that the light was good, and He separated the light from the darkness.                                                                 [god, saw, light, good, separated, darkness, god saw, light was good, separated the light]\n",
       "4          God called the light \"day,\" and the darkness he called \"night.\" And there was evening, and there was morning--the first day.                                           [god, called, light, darkness, evening, first, day, god called, first day, called the light, darkness he called]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df=result.selectExpr('text','unique_keywords').pandas_api()\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_db=result.selectExpr('text','unique_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgDF=spark.read.format(\"jdbc\").\\\n",
    "#     option(\"url\", \"jdbc:postgresql://192.168.1.39:5432/aiknowledge\").\\\n",
    "#     option(\"dbtable\", \"public.articles_articles\").\\\n",
    "#     option(\"user\", \"postgres\").\\\n",
    "#     option(\"password\", \"postgres\").\\\n",
    "#     option(\"driver\", \"org.postgresql.Driver\").load()    \n",
    "result_db.write.format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:postgresql://192.168.1.39:5432/aiknowledge\")\\\n",
    "    .option(\"dbtable\", \"public.bible\")\\\n",
    "    .option(\"user\", \"postgres\")\\\n",
    "    .option(\"password\", \"postgres\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8176,
     "status": "ok",
     "timestamp": 1664989465145,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "3V5ZoL_BACuy",
    "outputId": "c13509f2-4bc6-4134-8a0b-bdf0596b304a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "In the <span style=\"background-color: yellow;\">beginning</span> <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">created</span> the <span style=\"background-color: yellow;\">heavens</span> and the <span style=\"background-color: yellow;\">earth</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Now the <span style=\"background-color: yellow;\">earth</span> was <span style=\"background-color: yellow;\">formless</span> and <span style=\"background-color: yellow;\">empty</span>, <span style=\"background-color: yellow;\">darkness</span> was over the <span style=\"background-color: yellow;\">surface</span> of the <span style=\"background-color: yellow;\">deep</span>, and the <span style=\"background-color: yellow;\">Spirit</span> of <span style=\"background-color: yellow;\">God</span> was <span style=\"background-color: yellow;\">hovering</span> over the <span style=\"background-color: yellow;\">waters</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "And <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">said</span>, \"Let there be <span style=\"background-color: yellow;\">light</span>,\" and there was <span style=\"background-color: yellow;\">light</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">saw</span> that the <span style=\"background-color: yellow;\">light</span> was <span style=\"background-color: yellow;\">good</span>, and He <span style=\"background-color: yellow;\">separated</span> the <span style=\"background-color: yellow;\">light</span> from the <span style=\"background-color: yellow;\">darkness</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">called</span> the <span style=\"background-color: yellow;\">light</span> \"<span style=\"background-color: yellow;\">day</span>,\" and the <span style=\"background-color: yellow;\">darkness</span> he <span style=\"background-color: yellow;\">called</span> \"night.\" And there was <span style=\"background-color: yellow;\">evening</span>, and there was morning--the <span style=\"background-color: yellow;\">first</span> <span style=\"background-color: yellow;\">day</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "And <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">said</span>, \"Let there be an <span style=\"background-color: yellow;\">expanse</span> between the <span style=\"background-color: yellow;\">waters</span> to <span style=\"background-color: yellow;\">separate</span> <span style=\"background-color: yellow;\">water</span> from <span style=\"background-color: yellow;\">water</span>.\""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "So <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">made</span> the <span style=\"background-color: yellow;\">expanse</span> and <span style=\"background-color: yellow;\">separated</span> the <span style=\"background-color: yellow;\">water</span> under the <span style=\"background-color: yellow;\">expanse</span> from the <span style=\"background-color: yellow;\">water</span> above it. And it was so."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">called</span> the <span style=\"background-color: yellow;\">expanse</span> \"sky.\" And there was <span style=\"background-color: yellow;\">evening</span>, and there was morning--the <span style=\"background-color: yellow;\">second</span> <span style=\"background-color: yellow;\">day</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "And <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">said</span>, \"<span style=\"background-color: yellow;\">Let</span> the <span style=\"background-color: yellow;\">water</span> under the <span style=\"background-color: yellow;\">sky</span> be <span style=\"background-color: yellow;\">gathered</span> to <span style=\"background-color: yellow;\">one</span> <span style=\"background-color: yellow;\">place</span>, and <span style=\"background-color: yellow;\">let</span> <span style=\"background-color: yellow;\">dry</span> <span style=\"background-color: yellow;\">ground</span> appear.\" And it was so."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">called</span> the <span style=\"background-color: yellow;\">dry</span> <span style=\"background-color: yellow;\">ground</span> \"land,\" and the <span style=\"background-color: yellow;\">gathered</span> <span style=\"background-color: yellow;\">waters</span> he <span style=\"background-color: yellow;\">called</span> \"seas.\" And <span style=\"background-color: yellow;\">God</span> <span style=\"background-color: yellow;\">saw</span> that it was <span style=\"background-color: yellow;\">good</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in result.select(\"highlighted_keywords\").limit(10).collect():\n",
    "    display(HTML(r.highlighted_keywords))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        \n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        \n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        \n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        \n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        \n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>n</th><th>n_sq</th></tr><tr><td style=\"text-align:right\">1</td><td style=\"text-align:right\">1</td></tr><tr><td style=\"text-align:right\">2</td><td style=\"text-align:right\">4</td></tr><tr><td style=\"text-align:right\">3</td><td style=\"text-align:right\">9</td></tr></table>"
      ],
      "text/plain": [
       " n | n_sq \n",
       "---|------\n",
       " 1 |    1 \n",
       " 2 |    4 \n",
       " 3 |    9 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "graph = Graph(\"neo4j://localhost:7687\", auth=(\"daniel\", \"fighting\"),name=\"aiknowledge\")\n",
    "graph.run(\"UNWIND range(1, 3) AS n RETURN n, n * n as n_sq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=result.selectExpr(\"keywords.result as keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keywords_bible=keywords.rdd.flatMap(lambda x:np.concatenate(x)).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13339"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keywords_bible=set(keywords_bible)\n",
    "keywords_bible2=list(set(' '.join(keywords_bible).split()))\n",
    "len(keywords_bible2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "for word in keywords_bible2:\n",
    "    graph.create(Node(\"bible\",name = word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_ners = 'CREATE CONSTRAINT ners IF NOT EXISTS ON (n:NER) ASSERT n.name IS UNIQUE'\n",
    "graph.run(const_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664989465145,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "LEVYL7ffGfmX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f70b66c476b517a3398e503e066261bd5effd8e36d6bd83ebcc33f32092e45d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
